{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Interoperability Similarity\n",
    "\n",
    "* **Products used:** [ls8_usgs_sr_scene](https://explorer.digitalearth.africa/ls8_usgs_sr_scene), [sentinel1_ghana_monthly](https://explorer.digitalearth.africa/sentinel1_ghana_monthly), **s2a_msil2a**, **s2b_msil2a**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "There are a few water classifiers for Landsat, Sentinel-1, and Sentinel-2. We will examine WOfS for Landsat, thresholding for Sentinel-1, and WOfS for Sentinel-2.\n",
    "\n",
    "Although WOfS performs well on clear water bodies, it can misclassify murky water bodies as not water. WASARD or Sentinel-1 thresholding generally perform equally well or better than WOfS â€“ especially on murky water bodies.\n",
    "\n",
    "Because WOfS uses an optical data source (Landsat), it often does not have data to make water classifications due to cloud occlusion. The same limitation applies to Sentinel-2 water detection.\n",
    "\n",
    "The main reasons to use multiple data sources in the same water detection analysis are to increase temporal resolution and account for missing data.\n",
    "\n",
    "## Description\n",
    "\n",
    "This notebook checks how similar water classifications are among a selected set of sources (e.g. WOfS for Landsat, thresholding for Sentinel-1, etc.).\n",
    "These are the steps followed:\n",
    "\n",
    "1. Determine the dates of coincidence of data for the selected sensors using the CEOS COVE tool.\n",
    "1. Acquire water classifications for each sensor.\n",
    "1. Show the RGB representation of Time Slices and Water Classifications\n",
    "1. Obtain the intersected clean mask for the sensors.\n",
    "1. Show the per-time-slice percent of water (masked with the intersected clean mask) according to each sensor as a line plot.\n",
    "1. Show the per-time-slice similarity (% of matching pixels) of each pair of sensors as a line plot.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "**To run this analysis**, run all the cells in the notebook, starting with the \"Load packages\" cell.\n",
    "\n",
    "**After finishing the analysis**, return to the \"Analysis parameters\" cell, modify some values (e.g. choose a different location or time period to analyse) and re-run the analysis.\n",
    "There are additional instructions on modifying the notebook at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Load key Python packages and supporting functions for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import datacube\n",
    "import numpy\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from xarray.ufuncs import isnan as xr_nan\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "from deafrica_datahandling import load_ard\n",
    "from deafrica_plotting import display_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Activate the datacube database, which provides functionality for loading and displaying stored Earth observation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"water_interoperability_similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the length of time to conduct the analysis over.\n",
    "The parameters are\n",
    "\n",
    "* `latitude`: The latitude range to analyse (e.g. `(-11.288, -11.086)`).\n",
    "For reasonable loading times, make sure the range spans less than ~0.1 degrees.\n",
    "* `longitude`: The longitude range to analyse (e.g. `(130.324, 130.453)`).\n",
    "For reasonable loading times, make sure the range spans less than ~0.1 degrees.\n",
    "\n",
    "**If running the notebook for the first time**, keep the default settings below.\n",
    "This will demonstrate how the analysis works and provide meaningful results.\n",
    "The example covers an area around Obuasi, Ghana.\n",
    "\n",
    "**To run the notebook for a different area**, make sure Landsat 8, Sentinel-1, and Sentinel-2 data is available for the chosen area using the [DE Africa Sandbox Explorer](https://explorer.digitalearth.africa/ga_ls8c_gm_2_annual).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the area of interest\n",
    "# Obuasi, Ghana\n",
    "# latitude = (6.10, 6.26)\n",
    "# longitude = (-1.82, -1.66)\n",
    "latitude = (6.1582, 6.2028)\n",
    "longitude = (-1.7295, -1.6914)\n",
    "\n",
    "# The time range in which we want to determine \n",
    "# dates of close scenes among sensors.\n",
    "time_extents = ('2014-01-01', '2018-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f75189764e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deafrica_plotting import display_map\n",
    "\n",
    "display_map(longitude, latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the dates of coincidence of data for the selected sensors using the COVE tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a tool from the Committee on Earth Observations (CEOS) called the CEOS Visualization Environment (COVE). This tool has several applications, such as Acquisition Forecaster for determining what scenes areas will have and when, and Coverage Analyzer for determining what scenes areas have and when.\n",
    "\n",
    "For this analysis, we used the Coincident Calculator to determine when Landsat 8, Sentinel-1, and Sentinel-2 have close dates so we can compare them on a per-time-slice basis.\n",
    "\n",
    "The COVE Coincident Calculator (https://ceos-cove.org/en/coincident_calculator/) allows users to specify the sensors to determine coincidence for. For this analysis, we first determined the dates of coincidence of Landsat 8 and Sentinel-2. We then determined dates which are close to those which have Sentinel-1 data.\n",
    "\n",
    "We first found dates for which both Landsat 8 and Sentinel-2 data is available for the time range and area of interest, where were the following 8 dates:\n",
    "**[04-22-2017, 07-11-2017, 09-29-2017, 12-18-2017, 03-08-2018, 05-27-2018, 08-15-2018, 11-03-2018]**\n",
    "\n",
    "Then we found dates for which Landsat 8 and Sentinel-1 data is available for the time range and area of interest, and then found the subset of closely matching dates, which were the following 6 dates: **[07-12-2017 (off 1), 09-29-2017, 12-15-2017 (off 3), 03-09-2018 (off 1), 05-27-2018, 08-12-2018 (off 3)]** These are  the daets we use in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire water classifications for each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_load_params = dict(latitude=latitude, longitude=longitude, \n",
    "                          group_by='solar_day', \n",
    "                          output_crs=\"epsg:4326\",\n",
    "                          resolution=(-0.00027,0.00027))\n",
    "\n",
    "# The minimum fraction of data that a time slice must have\n",
    "# to be kept in this analysis\n",
    "MIN_FRAC_DATA = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the time range of overlapping data for all sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Landsat 8'] = dc.load(**common_load_params,\n",
    "                                product='ls8_usgs_sr_scene', \n",
    "                                time=time_extents, \n",
    "                                dask_chunks={'time':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Sentinel-1'] = dc.load(**common_load_params,\n",
    "                                 product='sentinel1_ghana_monthly', \n",
    "                                 time=time_extents, \n",
    "                                 dask_chunks={'time':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2a_meta = dc.load(**common_load_params,\n",
    "                   product='s2a_msil2a', \n",
    "                   time=time_extents, \n",
    "                   dask_chunks={'time':1})\n",
    "s2b_meta = dc.load(**common_load_params,\n",
    "                   product='s2b_msil2a', \n",
    "                   time=time_extents, \n",
    "                   dask_chunks={'time':1})\n",
    "metadata['Sentinel-2'] = xr.concat((s2a_meta, s2b_meta), dim='time').sortby('time')\n",
    "del s2a_meta, s2b_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_time_rng = metadata['Landsat 8'].time.values[[0,-1]]\n",
    "s2_time_rng = metadata['Sentinel-2'].time.values[[0,-1]]\n",
    "\n",
    "time_rng = np.stack((ls8_time_rng, s2_time_rng))\n",
    "overlapping_time = time_rng[:,0].max(), time_rng[:,1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.datetime64('2017-02-26T10:37:18.460000000'),\n",
       " numpy.datetime64('2017-12-02T10:21:37.599355000'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlapping_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limit the metadata to check for close scenes to the overlapping time range.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in metadata:\n",
    "    metadata[sensor] = metadata[sensor].sel(time=slice(*overlapping_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the dates of close scenes among the sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants #\n",
    "# The maximum number of days of difference between scenes\n",
    "# from sensors for those scenes to be considered approximately coincident.\n",
    "# The Sentinel-1 max date diff is set high enough to allow any set of dates \n",
    "# from the other sensors to match with one of its dates since we will \n",
    "# select its matching dates with special logic later.\n",
    "MAX_NUM_DAYS_DIFF = {'Landsat 8': 4, 'Sentinel-1':30, 'Sentinel-2':4}\n",
    "# End Constants #\n",
    "\n",
    "# all_times\n",
    "num_datasets = len(metadata)\n",
    "ds_names = list(metadata.keys())\n",
    "first_ds_name = ds_names[0]\n",
    "# All times for each dataset.\n",
    "ds_times = {ds_name: metadata[ds_name].time.values for ds_name in ds_names}\n",
    "# The time indices for each dataset's sorted time dimension \n",
    "# currently being compared.\n",
    "time_inds = {ds_name: 0 for ds_name in ds_names}\n",
    "corresponding_times = {ds_name: [] for ds_name in ds_names}\n",
    "\n",
    "# The index of the dataset in `metadata` to compare times against the first.\n",
    "oth_ds_ind = 1\n",
    "oth_ds_name = ds_names[oth_ds_ind]\n",
    "oth_ds_time_ind = time_inds[oth_ds_name]\n",
    "# For each time in the first dataset, find any \n",
    "# closely matching dates in the other datasets.\n",
    "for first_ds_time_ind, first_ds_time in enumerate(ds_times[first_ds_name]):\n",
    "    time_inds[first_ds_name] = first_ds_time_ind\n",
    "    # Find a corresponding time in this other dataset.\n",
    "    while True:\n",
    "        oth_ds_name = ds_names[oth_ds_ind]\n",
    "        oth_ds_time_ind = time_inds[oth_ds_name]\n",
    "        # If we've checked all dates for the other dataset, \n",
    "        # check the next first dataset time.\n",
    "        if oth_ds_time_ind == len(ds_times[oth_ds_name]):\n",
    "            break\n",
    "        oth_ds_time = metadata[ds_names[oth_ds_ind]].time.values[oth_ds_time_ind]\n",
    "        time_diff = (oth_ds_time - first_ds_time).astype('timedelta64[D]').astype(int)\n",
    "        \n",
    "        # If this other dataset time is too long before this\n",
    "        # first dataset time, check the next other dataset time.\n",
    "        if time_diff <= -MAX_NUM_DAYS_DIFF[oth_ds_name]:\n",
    "            oth_ds_time_ind += 1\n",
    "            time_inds[ds_names[oth_ds_ind]] = oth_ds_time_ind\n",
    "            continue\n",
    "        # If this other dataset time is within the acceptable range\n",
    "        # of the first dataset time...\n",
    "        elif abs(time_diff) <= MAX_NUM_DAYS_DIFF[oth_ds_name]:\n",
    "            # If there are more datasets to find a corresponding date for\n",
    "            # these current corresponding dates, check those datasets.\n",
    "            if oth_ds_ind < len(ds_names)-1:\n",
    "                oth_ds_ind += 1\n",
    "                continue\n",
    "            else: # Otherwise, record this set of corresponding dates.\n",
    "                for ds_name in ds_names:\n",
    "                    corresponding_times[ds_name].append(ds_times[ds_name][time_inds[ds_name]])\n",
    "                    # Don't use these times again.\n",
    "                    time_inds[ds_name] = time_inds[ds_name] + 1\n",
    "                oth_ds_ind = 1\n",
    "                break\n",
    "        # If this other dataset time is too long after this\n",
    "        # first dataset time, go to the next first dataset time.\n",
    "        else:\n",
    "            oth_ds_ind -= 1\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas datetime\n",
    "for sensor in corresponding_times:\n",
    "    for ind in range(len(corresponding_times[sensor])):\n",
    "        corresponding_times[sensor][ind] = \\\n",
    "            pd.to_datetime(corresponding_times[sensor][ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Sentinel-1 data is a monthly composite, so we need special logic for choosing data from it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_pd_datetimes = corresponding_times['Landsat 8'] \n",
    "s1_pd_datetimes = pd.to_datetime(metadata['Sentinel-1'].time.values)\n",
    "for time_ind, ls8_time in enumerate(ls8_pd_datetimes):\n",
    "    matching_s1_time_ind = [s1_time_ind for (s1_time_ind, s1_time) \n",
    "                            in enumerate(s1_pd_datetimes) if \n",
    "                            s1_time.month == ls8_time.month][0]\n",
    "    matching_s1_time = metadata['Sentinel-1'].time.values[matching_s1_time_ind]\n",
    "    corresponding_times['Sentinel-1'][time_ind] = pd.to_datetime(matching_s1_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landsat 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_times = corresponding_times['Landsat 8']\n",
    "s1_times = corresponding_times['Sentinel-1']\n",
    "s2_times = corresponding_times['Sentinel-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ee24635dc3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mls8_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m ls8_data = dc.load(**common_load_params,\n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0mproduct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ls8_usgs_sr_scene'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls8_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls8_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    dask_chunks = {'time': 1})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dc' is not defined"
     ]
    }
   ],
   "source": [
    "ls8_data = []\n",
    "ls8_data = dc.load(**common_load_params,\n",
    "                   product='ls8_usgs_sr_scene', \n",
    "                   time=(ls8_times[0], ls8_times[-1]),\n",
    "                   dask_chunks = {'time': 1})\n",
    "ls8_data = ls8_data.sel(time=corresponding_times['Landsat 8'], method='nearest')\n",
    "print(f\"Subset the data to {len(ls8_data.time)} times of near coincidence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire the clean mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_not_nan_da = ~xr_nan(ls8_data).to_array()\n",
    "ls8_clean_mask = ls8_not_nan_da.min('variable')\n",
    "del ls8_not_nan_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire water classifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from water_interoperability_utils.dc_water_classifier import wofs_classify\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "    ls8_water = wofs_classify(ls8_data).wofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset the data to 7 times of near coincidence.\n"
     ]
    }
   ],
   "source": [
    "s1_data = dc.load(**common_load_params,\n",
    "                  product='sentinel1_ghana_monthly', \n",
    "                  time=(s1_times[0], s1_times[-1]),\n",
    "                  dask_chunks = {'time': 1})\n",
    "s1_data = s1_data.sel(time=corresponding_times['Sentinel-1'], method='nearest')\n",
    "print(f\"Subset the data to {len(s1_data.time)} times of near coincidence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire the clean mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_not_nan_da = ~xr_nan(s1_data).to_array()\n",
    "s1_clean_mask = s1_not_nan_da.min('variable')\n",
    "del s1_not_nan_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire water classifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from skimage.filters import try_all_threshold, threshold_otsu\n",
    "\n",
    "thresh_vv = threshold_otsu(s1_data.vv.values)\n",
    "thresh_vh = threshold_otsu(s1_data.vh.values)\n",
    "\n",
    "binary_vv = s1_data.vv.values < thresh_vv\n",
    "binary_vh = s1_data.vh.values < thresh_vh\n",
    "\n",
    "s1_water = xr.DataArray(binary_vv & binary_vh, coords=s1_data.vv.coords, \n",
    "                        dims=s1_data.vv.dims, attrs=s1_data.vv.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting the data to 7 times of near coincidence.\n"
     ]
    }
   ],
   "source": [
    "s2a_data = dc.load(**common_load_params,\n",
    "                   product='s2a_msil2a', \n",
    "                   time=(s2_times[0], s2_times[-1]),\n",
    "                   dask_chunks = {'time': 1})\n",
    "s2b_data = dc.load(**common_load_params,\n",
    "                   product='s2b_msil2a', \n",
    "                   time=(s2_times[0], s2_times[-1]),\n",
    "                   dask_chunks = {'time': 1})\n",
    "s2_data = xr.concat((s2a_data, s2b_data), dim='time').sortby('time')\n",
    "s2_data = s2_data.sel(time=corresponding_times['Sentinel-2'], method='nearest')\n",
    "print(f\"Subsetting the data to {len(s2_data.time)} times of near coincidence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire the clean mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See figure 3 on this page for more information about the\n",
    "# values of the scl data for Sentinel-2: \n",
    "# https://earth.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm\n",
    "s2_clean_mask = s2_data.scl.isin([1, 2, 3, 4, 5, 6, 7, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data = s2_data.astype(np.float32).where(s2_clean_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire water classifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "    s2_water = wofs_classify(s2_data.rename(\n",
    "        {'nir_1': 'nir', 'swir_1': 'swir1', 'swir_2': 'swir2'})).wofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_data = ls8_data.compute()\n",
    "ls8_clean_mask = ls8_clean_mask.compute()\n",
    "\n",
    "s1_data = s1_data.compute()\n",
    "s1_clean_mask = s1_clean_mask.compute()\n",
    "\n",
    "s2_data = s2_data.compute()\n",
    "s2_clean_mask = s2_clean_mask.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the RGB Representation of Time Slices and Water Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain the intersected clean mask for the sensors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersected_clean_mask = xr.DataArray((ls8_clean_mask.values & \n",
    "                                      s1_clean_mask.values & \n",
    "                                      s2_clean_mask.values), \n",
    "                                      coords=ls8_clean_mask.coords, \n",
    "                                      dims=ls8_clean_mask.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show the data and water classifications for each sensor as the data will be compared among them (an intersection).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the per-time-slice percent of water according to each sensor as a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the per-time-slice similarity (% of matching pixels) of each pair of sensors as a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "7073445e337f46189cb5f163631ca8d5": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     },
     "908a9dc9117c40a58c0270b0ac5c49f4": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
